{
 "cells": [
  {
   "cell_type": "raw",
   "id": "21de563d",
   "metadata": {},
   "source": [
    "---\n",
    "{\"publish\":true,\"title\":\"Constructing Confidence Interval\",\"created\":\"2025-05-26T20:56:19\",\"modified\":\"2025-06-07T09:16:56\",\"cssclasses\":\"\",\"state\":\"done\",\"sup\":[\"[[Confidence Interval]]\"],\"alias\":null,\"type\":\"jupyter\"}\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba122eb5",
   "metadata": {},
   "source": [
    "\n",
    "# Constructing Confidence Interval\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/zcysxy/quartz/blob/v4/content/jupyter/Constructing%20Confidence%20Interval.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook explores methods of constructing [[Confidence Interval]]s. We focus on the following methods:\n",
    "\n",
    "1. Exact calculation\n",
    "2. [[Central Limit Theorem\\|CLT]] CI\n",
    "3. Hoeffding CI\n",
    "4. Plug-in (Wald) CI\n",
    "5. Wilson score CI\n",
    "\n",
    "We focus on the example of estimating the mean of a Bernoulli distribution with parameter $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c366da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting aesthetics\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sampler\n",
    "sampler = lambda n, p: np.random.binomial(1, p, size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce4ed6",
   "metadata": {},
   "source": [
    "## Test Statistic and Critical Values\n",
    "\n",
    "Recall that a [[Statistic]] is a function of the observed data, e.g., mean and variance.\n",
    "If a test involves some parameters, a test statistic is often a function of both the sample and the parameter, such that\n",
    "\n",
    "- the distribution of $t$ is known, e.g., a [[t Distribution]] or a [[Chi-Square Distribution]], or can be approximated, e.g., using [[Central Limit Theorem\\|CLT]] ^known\n",
    "- the distribution of $t$ does not depend on the parameter ^unkown\n",
    "\n",
    "Such a test statistic is also called a *pivot (quantity)*.\n",
    "\n",
    "Then, we can first construct a confidence interval for the test statistic $t$.\n",
    "Using the knowledge of its distribution (or quantiles), the confidence interval can be given by:\n",
    "$$\n",
    "P(c_{\\alpha /2} \\leq t \\leq c_{1-\\alpha /2}) = 1-\\alpha \n",
    "$$\n",
    "where $c_{q}$ is the $q$-th quantile of the distribution of $t$, and $c_{\\alpha/2}$ and $c_{1-\\alpha /2}$ are called the *critical values*.\n",
    "\n",
    "## Exact CI\n",
    "\n",
    "Exact CIs are constructed using known quantile function $c_{q}$ and explicit expression of the test statistic $t$.\n",
    "\n",
    "> [!tip] Warm up\n",
    "> Construct the exact CI of estimating $\\theta$ with 10 iid samples from $\\mathcal{N}(\\theta,5)$. Use the look-up table of the Normal distribution quantiles.\n",
    "\n",
    "For Bernoulli trials, let's consider the sum of $n$ trials, $S_n = \\sum_{i=1}^{n} X_i$, as the test statistic. $S_n$ follows a Binomial distribution, whose CDF satisfies:\n",
    "$$\n",
    "F_{\\mathrm{binom}}\\left( t; n,p \\right)  = F_{\\mathrm{beta}}(p; t+1, n+1-t).\n",
    "$$\n",
    "where $F_{\\mathrm{beta}}(\\cdot;\\alpha,\\beta)$ is the CDF of the Beta distribution with parameters $\\alpha$ and $\\beta$.\n",
    "Therefore, using exact beta distribution quantiles, a $1-\\alpha$ level exact CI for $p$ is\n",
    "$$\n",
    "C^{(\\mathrm{exact})}(S_n) = [b_{\\alpha /2}(S_n,n-S_n+1), b_{1-\\alpha /2}(S_n+1,n-S_n)],\n",
    "$$\n",
    "where $b_{q}(\\alpha,\\beta)$ is the $q$-th quantile of the Beta distribution with parameters $\\alpha$ and $\\beta$.\n",
    "\n",
    "> [!rmk] Remark\n",
    "> Note that $p$ is **not a random variable**. However, treating it as a beta random variable (as in a Bayesian interpretation) gives us the same exact calculation as using the binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "def exact_ci(s, n, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compute the exact confidence interval for a Bernoulli parameter p\n",
    "    using the Beta quantile representation of the Binomial CDF.\n",
    "\n",
    "    Parameters:\n",
    "    - s: int, number of successes (sum of Bernoulli trials)\n",
    "    - n: int, number of trials\n",
    "    - alpha: significance level\n",
    "\n",
    "    Returns:\n",
    "    - (lower_bound, upper_bound): tuple of floats\n",
    "    \"\"\"\n",
    "    if s == 0:\n",
    "        lower = 0.0\n",
    "    else:\n",
    "        lower = beta.ppf(alpha / 2, s, n - s + 1)\n",
    "        \n",
    "    if s == n:\n",
    "        upper = 1.0\n",
    "    else:\n",
    "        upper = beta.ppf(1 - alpha / 2, s + 1, n - s)\n",
    "\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate exact CI coverage as sample size increases\n",
    "\n",
    "p = 0.7\n",
    "sample_sizes = np.unique(np.round(np.logspace(1, 3, num=15)).astype(int))\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "point_estimates = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    samples = sampler(n, p)\n",
    "    s = np.sum(samples)\n",
    "    lower, upper = exact_ci(s, n)\n",
    "    \n",
    "    lower_bounds.append(lower)\n",
    "    upper_bounds.append(upper)\n",
    "    point_estimates.append(s / n)\n",
    "\n",
    "# Plotting\n",
    "def plot_ci(sample_sizes, lower_bounds, upper_bounds, point_estimates, p_true, method_name):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(sample_sizes, point_estimates, label='Empirical Mean', color='black', linestyle='--', marker='o')\n",
    "    plt.plot(sample_sizes, lower_bounds, label='Lower Bound', color='blue')\n",
    "    plt.plot(sample_sizes, upper_bounds, label='Upper Bound', color='red')\n",
    "    plt.fill_between(sample_sizes, lower_bounds, upper_bounds, color='blue', alpha=0.2)\n",
    "    plt.axhline(p_true, color='green', linestyle=':', label=f'True p = {p_true}')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Sample Size (n)')\n",
    "    plt.ylabel('Estimated p with CI')\n",
    "    plt.title(f'{method_name} vs Log-Spaced Sample Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "    return fig\n",
    "\n",
    "fig = plot_ci(sample_sizes, lower_bounds, upper_bounds, point_estimates, p, 'Exact CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ci_method(ci_function, p, sample_sizes, num_trials=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Evaluate a CI method over multiple sample sizes.\n",
    "    \n",
    "    Parameters:\n",
    "    - ci_function: function that returns (lower, upper) given (s, n, alpha)\n",
    "    - p: float, true parameter of the Bernoulli distribution\n",
    "    - sample_sizes: array-like of integers, sample sizes to evaluate\n",
    "    - num_trials: int, number of Monte Carlo repetitions\n",
    "    - alpha: float, significance level\n",
    "    \n",
    "    Returns:\n",
    "    - result: dict with keys 'n', 'avg_length', 'coverage'\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_lengths = []\n",
    "    coverages = []\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        lengths = []\n",
    "        hits = []\n",
    "        \n",
    "        for _ in range(num_trials):\n",
    "            samples = sampler(n, p)\n",
    "            s = np.sum(samples)\n",
    "            lower, upper = ci_function(s, n, alpha=alpha)\n",
    "            lengths.append(upper - lower)\n",
    "            hits.append(lower <= p <= upper)\n",
    "        \n",
    "        avg_lengths.append(np.mean(lengths))\n",
    "        coverages.append(np.mean(hits))\n",
    "    \n",
    "    return {\n",
    "        'n': sample_sizes,\n",
    "        'avg_length': avg_lengths,\n",
    "        'coverage': coverages\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exact = evaluate_ci_method(exact_ci, p, sample_sizes, num_trials=int(1e3))\n",
    "\n",
    "def plot_stat(results, method_name, alpha=0.05):\n",
    "    n_vals = results['n']\n",
    "    avg_lengths = results['avg_length']\n",
    "    coverages = results['coverage']\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Average Length\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(n_vals, avg_lengths, marker='o', color='blue')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.plot(n_vals, 1 / np.sqrt(n_vals), linestyle='--', color='gray', label='$n^{-1/2}$')\n",
    "    plt.xlabel('Sample Size (n)')\n",
    "    plt.ylabel('Average CI Length')\n",
    "    plt.title(f'{method_name}: Average CI Length vs Sample Size')\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "\n",
    "    # Coverage\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(n_vals, coverages, marker='s', color='green')\n",
    "    plt.axhline(1 - alpha, color='red', linestyle='--', label=f'Nominal Level = {1 - alpha:.2f}')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Sample Size (n)')\n",
    "    plt.ylabel('Empirical Coverage')\n",
    "    plt.title(f'{method_name}: Coverage vs Sample Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_stat(results_exact, 'Exact CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f35d1",
   "metadata": {},
   "source": [
    "## CLT CI\n",
    "\n",
    "By CLT and LLN, we know that\n",
    "$$\n",
    "\\frac{\\sqrt{ n }(\\overline{X}-p)}{\\hat{\\sigma}} \\overset{ d }{ \\to } \\mathcal{N}(0,1),\n",
    "$$\n",
    "where $\\overline{X}$ is the sample mean and $\\hat{\\sigma}^{2} =\\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}$ is the sample variance.\n",
    "This gives the CLT CI:\n",
    "$$\n",
    "C^{(\\mathrm{CLT})}(X) = \\overline{X} \\pm z_{\\alpha /2}\\frac{\\hat{\\sigma}}{\\sqrt{ n }}.\n",
    "$$\n",
    "where $z_{\\beta}$ is the $\\beta$-th quantile of the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ad014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def clt_ci(s, n, alpha=0.05):\n",
    "    X_bar = s / n\n",
    "    sigma_hat_sq = (s * (1-X_bar)**2 + (n - s) * X_bar**2) / (n - 1)\n",
    "    z = norm.ppf(1 - alpha / 2)\n",
    "    half_width = z * np.sqrt(sigma_hat_sq / n)\n",
    "    return (X_bar - half_width, X_bar + half_width)\n",
    "\n",
    "# Run pointwise simulation with log-spaced n\n",
    "lower_bounds, upper_bounds, point_estimates = [], [], []\n",
    "for n in sample_sizes:\n",
    "    samples = sampler(n, p)\n",
    "    s = np.sum(samples)\n",
    "    lower, upper = clt_ci(s, n)\n",
    "    lower_bounds.append(lower)\n",
    "    upper_bounds.append(upper)\n",
    "    point_estimates.append(s / n)\n",
    "\n",
    "\n",
    "fig = plot_ci(sample_sizes, lower_bounds, upper_bounds, point_estimates, p, 'CLT CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f50cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clt = evaluate_ci_method(clt_ci, p, sample_sizes, num_trials=int(1e3))\n",
    "\n",
    "fig = plot_stat(results_clt, 'CLT CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7c36a",
   "metadata": {},
   "source": [
    "We can see that both exact CI and CLT CI have an average length of order $n^{-1/2}$.\n",
    "However, CLT CI is only asymptotically valid.\n",
    "\n",
    "## Hoeffding CI\n",
    "\n",
    "Since Bernoulli trials are bounded, Hoeffding's inequality gives\n",
    "$$\n",
    "P\\left( \\left| \\overline{X}-p \\right| \\ge t \\right) \\le 2\\exp\\left( -2 n t^{2} \\right),\n",
    "$$\n",
    "leading to a $1-\\alpha$ level CI:\n",
    "$$\n",
    "C^{(\\mathrm{Hoeff})}(\\overline{X}) = \\overline{X} \\pm \\sqrt{\\frac{\\log(2/\\alpha)}{2n}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89eb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoeffding_ci(s, n, alpha=0.05):\n",
    "    X_bar = s / n\n",
    "    half_width = np.sqrt(np.log(2 / alpha) / (2 * n))\n",
    "    return (X_bar - half_width, X_bar + half_width)\n",
    "\n",
    "# Run pointwise simulation with log-spaced n\n",
    "lower_bounds, upper_bounds, point_estimates = [], [], []\n",
    "for n in sample_sizes:\n",
    "    samples = sampler(n, p)\n",
    "    s = np.sum(samples)\n",
    "    lower, upper = hoeffding_ci(s, n)\n",
    "    lower_bounds.append(lower)\n",
    "    upper_bounds.append(upper)\n",
    "    point_estimates.append(s / n)\n",
    "\n",
    "\n",
    "fig = plot_ci(sample_sizes, lower_bounds, upper_bounds, point_estimates, p, 'Hoeffding CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hoeff = evaluate_ci_method(hoeffding_ci, p, sample_sizes, num_trials=int(1e3))\n",
    "fig = plot_stat(results_hoeff, 'Hoeffding CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ee679",
   "metadata": {},
   "source": [
    "We can see Hoeffding CI is super *conservative*: it has a much wider CI with a higher coverage than the nominal level.\n",
    "\n",
    "> [!ex] Chebyshev CI\n",
    "> Construct another concentration inequality-based CI. For example, Chebyshev CI. And compare it with Hoeffding CI.\n",
    "\n",
    "## Wald CI\n",
    "\n",
    "Another version of CLT CI is using the fact that\n",
    "$$\n",
    "\\frac{\\hat{\\theta}-\\theta}{\\mathrm{SE}(\\hat{\\theta} )} \\overset{ d }{ \\to } \\mathcal{N}(0,1),\n",
    "$$\n",
    "where $\\mathrm{SE}$ is the *standard error* of the statistic $\\hat{\\theta}$.\n",
    "For sample mean, we know its standard error is\n",
    "$$\n",
    "\\mathrm{SE}(\\overline{X}) = \\frac{\\operatorname{Var}(X_{i})}{\\sqrt{ n }}.\n",
    "$$\n",
    "For Bernoulli distribution, instead of using a sample variance to estimate the variance, and hence estimate the standard error, as we did in constructing [CLT CI](#clt-ci), we notice that\n",
    "$$\n",
    "\\operatorname{Var}(X_i) = p(1-p).\n",
    "$$\n",
    "Thus, we can estimate the standard error by **plugging in** the estimation of $p$ instead, using $\\hat{p} = \\overline{X}$, giving the Wald plug-in CI:\n",
    "$$\n",
    "C^{(\\mathrm{Wald})}(X) = \\overline{X} \\pm z_{\\alpha /2} \\sqrt{\\frac{\\overline{X}(1-\\overline{X})}{n}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c08df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wald_ci(s, n, alpha=0.05):\n",
    "\t\tX_bar = s / n\n",
    "\t\thalf_width = norm.ppf(1 - alpha / 2) * np.sqrt(X_bar * (1 - X_bar) / n)\n",
    "\t\treturn (X_bar - half_width, X_bar + half_width)\n",
    "\n",
    "# Run pointwise simulation with log-spaced n\n",
    "lower_bounds, upper_bounds, point_estimates = [], [], []\n",
    "for n in sample_sizes:\n",
    "\t\tsamples = sampler(n, p)\n",
    "\t\ts = np.sum(samples)\n",
    "\t\tlower, upper = wald_ci(s, n)\n",
    "\t\tlower_bounds.append(lower)\n",
    "\t\tupper_bounds.append(upper)\n",
    "\t\tpoint_estimates.append(s / n)\n",
    "\n",
    "fig = plot_ci(sample_sizes, lower_bounds, upper_bounds, point_estimates, p, 'Wald CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53308c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wald = evaluate_ci_method(wald_ci, p, sample_sizes, num_trials=int(1e3))\n",
    "fig = plot_stat(results_wald, 'Wald CI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8cc5b",
   "metadata": {},
   "source": [
    "Since Wald CI also uses CLT, it behaves similarly to CLT CI.\n",
    "\n",
    "## Wilson Score CI\n",
    "\n",
    "Left as exercise\n",
    "\n",
    "## Comparison\n",
    "\n",
    "We now compare the average length and coverage of the confidence intervals constructed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90348fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ci_comparison(all_results, method_names, alpha=0.05):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Average Length Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for results, name in zip(all_results, method_names):\n",
    "        plt.plot(results['n'], results['avg_length'], marker='o', label=name)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Sample Size (n)')\n",
    "    plt.ylabel('Average CI Length')\n",
    "    plt.title('Average CI Length vs Sample Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Coverage Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for results, name in zip(all_results, method_names):\n",
    "        plt.plot(results['n'], results['coverage'], marker='s', label=name)\n",
    "    plt.axhline(1 - alpha, color='red', linestyle='--', label=f'Nominal Level = {1 - alpha:.2f}')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Sample Size (n)')\n",
    "    plt.ylabel('Empirical Coverage')\n",
    "    plt.title('Coverage vs Sample Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_ci_comparison(\n",
    "    [results_exact, results_clt, results_hoeff, results_wald],\n",
    "    [\"Exact CI\", \"CLT CI\", \"Hoeffding CI\", \"Wald CI\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a93ff7",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Summary of the methodology behind the above methods:\n",
    "\n",
    "- Exact calculation is finite-sample valid, preferred when the test statistic's distribution is known and easy to compute. Not practical for unknown distributions.\n",
    "- CLT CI uses [[Central Limit Theorem]] and thus is asymptotically valid. It is preferred when the sample size is large. It does not leverage any structural information about the distribution.\n",
    "- Hoeffding CI is one example of a concentration inequality-based CI. This class of CIs is finite-sample valid. Any concentration inequality can be used to construct a CI, and some are more suitable for specific distributions. Generally, concentration inequality-based CIs are more conservative.\n",
    "- Wald CI uses the plug-in principle, which is asymptotically valid. It is preferred when the test statistic involves parameters that can be readily estimated; then the estimation is plugged into the CI formula.\n",
    "- Wilson score CI constructs the CI by *solving* the inequality by CLT or other concentration inequalities. It leverages the structure of the test statistic but is preferred only when the inequality can be solved easily.\n",
    "\n",
    "The width of the confidence interval, that is, its accuracy, depends on:\n",
    "\n",
    "- The sample size n: the larger the sample size the narrow the width of the CI.\n",
    "- The confidence level: the higher the confidence the wider the CI will be!\n",
    "- The standard deviation of the population or SE: the larger the SE the wider the CI will be.\n",
    "- The method used to construct the CI"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
